# ğŸŒ JSON Selective Translator with Ollama

Un outil Python avec interface Gradio pour traduire sÃ©lectivement des clÃ©s JSON spÃ©cifiques en utilisant des modÃ¨les Ollama locaux.

## âœ¨ FonctionnalitÃ©s

### Principales
- ğŸ¯ **Traduction sÃ©lective** : Traduisez uniquement les clÃ©s JSON que vous spÃ©cifiez
- ğŸ¤– **Ollama local** : Utilise des modÃ¨les d'IA locaux (aucune API externe requise)
- ğŸ¨ **Interface Gradio** : Interface web intuitive et moderne
- ğŸ”„ **Support des chemins imbriquÃ©s** : `user.profile.description`, `items[0].title`
- ğŸ­ **Patterns regex** : `*.description` pour toutes les clÃ©s "description"
- ğŸ’¾ **Cache intelligent** : Ã‰vite les traductions redondantes
- ğŸ”’ **PrÃ©servation des variables** : ProtÃ¨ge `{{var}}`, `{var}`, `%s`, etc.

### AvancÃ©es
- ğŸ‘ï¸ **Mode dry-run** : PrÃ©visualisez les clÃ©s qui seront traduites
- ğŸ“Š **Barre de progression** : Suivi en temps rÃ©el
- ğŸ“‹ **Export de logs** : Historique complet des traductions
- âœ… **Validation JSON** : VÃ©rification automatique de la validitÃ©
- ğŸ¯ **Traduction par lots** : Optimisation pour les grandes structures

## ğŸš€ Installation

### PrÃ©requis
1. **Python 3.8+**
2. **Ollama** installÃ© et en cours d'exÃ©cution

#### Installation d'Ollama
```bash
# Windows, macOS, Linux
# TÃ©lÃ©chargez depuis https://ollama.ai

# Puis installez un modÃ¨le (exemple avec llama2)
ollama pull llama2

# Ou avec mistral (recommandÃ© pour le franÃ§ais)
ollama pull mistral

# Ou avec mixtral pour de meilleures performances
ollama pull mixtral
```

### Installation du script
```bash
# Clonez ou tÃ©lÃ©chargez les fichiers
cd "Markdown Translate"

# Installez les dÃ©pendances Python
pip install -r requirements.txt
```

## ğŸ“– Utilisation

### Lancement
```bash
python json_translator.py
```

L'interface Gradio s'ouvrira automatiquement dans votre navigateur Ã  l'adresse `http://127.0.0.1:7860`

### Guide pas Ã  pas

1. **Chargez votre fichier JSON**
   - Cliquez sur "Upload JSON File"
   - SÃ©lectionnez votre fichier `.json`
   - Le JSON s'affiche dans l'onglet "Source JSON"

2. **Configurez la traduction**
   - SÃ©lectionnez le **modÃ¨le Ollama** (ex: `mistral`, `llama2`)
   - Choisissez la **langue cible** (franÃ§ais, anglais, espagnol, etc.)

3. **SpÃ©cifiez les clÃ©s Ã  traduire**
   ```
   title
   description
   user.profile.bio
   items[0].content
   *.text
   sections.*.description
   ```

4. **Options**
   - â˜‘ï¸ Cochez "Dry Run" pour prÃ©visualiser sans traduire
   - ğŸš€ Cliquez sur "Translate"

5. **Consultez les rÃ©sultats**
   - Onglet "Translated JSON" : JSON traduit
   - Onglet "Selected Keys" : Liste des clÃ©s traitÃ©es
   - Statut : Informations sur la traduction

6. **TÃ©lÃ©chargez le rÃ©sultat**
   - Cliquez sur "Download Translated JSON"
   - Exportez les logs avec "Export Translation Log"

## ğŸ¯ Exemples de patterns de clÃ©s

### Patterns simples
```
title                 # Toutes les clÃ©s "title" Ã  n'importe quel niveau
description          # Toutes les clÃ©s "description"
author               # Toutes les clÃ©s "author"
```

### Chemins imbriquÃ©s
```
user.name            # "name" dans l'objet "user"
user.profile.bio     # "bio" dans "user.profile"
config.app.title     # "title" dans "config.app"
```

### Tableaux
```
items[0].title       # "title" du premier Ã©lÃ©ment de "items"
users[2].description # "description" du troisiÃ¨me utilisateur
```

### Wildcards (*)
```
*.description        # Toutes les clÃ©s "description" Ã  n'importe quel niveau
user.*.name          # Toutes les clÃ©s "name" sous "user"
sections.*.title     # Tous les "title" dans "sections"
**.content           # "content" Ã  n'importe quelle profondeur
```

### Regex avancÃ©
```
^(title|name)$       # ClÃ©s "title" OU "name"
.*_text$             # ClÃ©s se terminant par "_text"
```

## ğŸ“ Exemple JSON

CrÃ©ez un fichier `example.json` :

```json
{
  "title": "Welcome to my website",
  "description": "This is a great website about {{topic}}",
  "author": {
    "name": "John Doe",
    "bio": "Software developer passionate about %s"
  },
  "sections": [
    {
      "heading": "About Us",
      "content": "We are a team of {count} developers",
      "metadata": {
        "created": "2024-01-01",
        "id": 123
      }
    },
    {
      "heading": "Contact",
      "content": "Reach us at contact@example.com"
    }
  ],
  "config": {
    "version": "1.0.0",
    "debug": false
  }
}
```

**ClÃ©s Ã  traduire :**
```
title
description
author.bio
sections.*.heading
sections.*.content
```

**RÃ©sultat** : Les textes sont traduits, mais :
- `author.name` reste "John Doe" (non spÃ©cifiÃ©)
- `config.version` reste "1.0.0" (non spÃ©cifiÃ©)
- Les variables `{{topic}}`, `%s`, `{count}` sont prÃ©servÃ©es
- Les mÃ©tadonnÃ©es et IDs restent intacts

## âš™ï¸ Configuration avancÃ©e

### Variables prÃ©servÃ©es automatiquement
Le script dÃ©tecte et prÃ©serve automatiquement :
- `{{variable}}` - Double accolades
- `{variable}` - Accolades simples
- `%(variable)s`, `%(name)d` - Python format
- `%s`, `%d` - Printf style
- `${variable}` - Shell style
- `[[variable]]` - Double crochets

### Cache de traduction
- Les traductions identiques sont mises en cache
- RÃ©duit le temps de traduction et les appels API
- Utilisez "Clear Cache" pour vider le cache

### ModÃ¨les Ollama recommandÃ©s

**Pour le franÃ§ais :**
- `mistral` - Excellent pour le franÃ§ais (7B paramÃ¨tres)
- `mixtral` - TrÃ¨s haute qualitÃ© (47B paramÃ¨tres, plus lent)
- `llama2` - Bon Ã©quilibre (7B/13B/70B)

**Pour d'autres langues :**
- `gemma` - Multilingue Google
- `vicuna` - Fine-tunÃ© pour conversations

```bash
# Installer plusieurs modÃ¨les
ollama pull mistral
ollama pull mixtral
ollama pull llama2
```

## ğŸ”§ DÃ©pannage

### "No Ollama models found"
```bash
# VÃ©rifiez qu'Ollama est en cours d'exÃ©cution
ollama list

# Installez un modÃ¨le si nÃ©cessaire
ollama pull mistral
```

### "Cannot connect to Ollama"
```bash
# VÃ©rifiez le service Ollama
# Windows : Cherchez "Ollama" dans les services
# Linux/Mac :
ollama serve
```

### Erreur de mÃ©moire
```bash
# Utilisez un modÃ¨le plus petit
ollama pull mistral:7b-instruct

# Ou libÃ©rez de la mÃ©moire
ollama rm <model-name>
```

### Traductions de mauvaise qualitÃ©
1. Essayez un autre modÃ¨le (mistral ou mixtral recommandÃ©s)
2. VÃ©rifiez que les clÃ©s spÃ©cifiÃ©es sont correctes
3. Utilisez le mode dry-run pour vÃ©rifier les clÃ©s sÃ©lectionnÃ©es

## ğŸ“Š Statistiques et logs

### Pendant la traduction
- Barre de progression avec nombre de clÃ©s traitÃ©es
- Affichage du texte en cours de traduction
- Statistiques de cache (hits/misses)

### AprÃ¨s la traduction
- Nombre total de traductions effectuÃ©es
- Nombre de clÃ©s modifiÃ©es
- Ratio cache hits/misses

### Export de logs
Cliquez sur "Export Translation Log" pour gÃ©nÃ©rer un fichier texte contenant :
- Toutes les traductions effectuÃ©es
- Horodatage de chaque traduction
- Langue cible utilisÃ©e
- Texte source et traduit
- Statistiques du cache

## ğŸ—ï¸ Architecture du code

```
json_translator.py
â”œâ”€â”€ TranslationCache        # Cache en mÃ©moire avec hash MD5
â”œâ”€â”€ VariablePreserver       # DÃ©tection et protection des variables
â”œâ”€â”€ JSONKeySelector         # SÃ©lection des clÃ©s avec patterns/regex
â”œâ”€â”€ OllamaTranslator       # Moteur de traduction principal
â””â”€â”€ create_gradio_interface # Interface utilisateur Gradio
```

### Classes principales

**TranslationCache**
- Stockage des traductions en mÃ©moire
- ClÃ© : hash(texte + langue + modÃ¨le)
- Statistiques hits/misses

**VariablePreserver**
- DÃ©tecte les patterns de variables
- Les remplace par des placeholders pendant la traduction
- Les restaure aprÃ¨s traduction

**JSONKeySelector**
- Flatten le JSON en notation point
- Match les patterns (wildcards, regex)
- Reconstruction du JSON avec valeurs traduites

**OllamaTranslator**
- Appels Ã  l'API Ollama locale
- Gestion du cache et des variables
- Traduction par lots
- Export de logs

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- Signaler des bugs
- Proposer de nouvelles fonctionnalitÃ©s
- AmÃ©liorer la documentation

## ğŸ“„ Licence

Ce projet est libre d'utilisation pour des projets personnels et commerciaux.

## ğŸ™ Remerciements

- [Ollama](https://ollama.ai) - ModÃ¨les d'IA locaux
- [Gradio](https://gradio.app) - Interface web Python
- CommunautÃ© open source

## ğŸ“ Support

Pour des questions ou de l'aide :
1. Consultez la section DÃ©pannage ci-dessus
2. VÃ©rifiez que toutes les dÃ©pendances sont installÃ©es
3. Assurez-vous qu'Ollama fonctionne correctement

---

**Bon Ã  savoir :**
- âœ… Fonctionne 100% en local (aucune connexion internet requise)
- âœ… Pas de limite d'utilisation
- âœ… ConfidentialitÃ© totale des donnÃ©es
- âœ… Support multilingue
- âœ… Gratuit et open source
